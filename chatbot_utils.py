import google.generativeai as genai
import streamlit as st
import pandas as pd
import os
import json

def configure_genai():
    """Configures the Gemini API key from Streamlit secrets or environment variables."""
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except (FileNotFoundError, KeyError):
        api_key = os.getenv("GOOGLE_API_KEY")
    
    if not api_key:
        return False
    
    genai.configure(api_key=api_key)
    return True

def get_data_context(df):
    """
    Generates a concise summary of the dataframe for the LLM.
    Includes column names, date range, and a sample of recent reviews.
    """
    if df is None or df.empty:
        return "No underlying data available."
    
    buffer = []
    buffer.append(f"TOTAL REVIEWS IN DATASET: {len(df)}")
    
    if 'review_date' in df.columns:
        min_date = df['review_date'].min()
        max_date = df['review_date'].max()
        buffer.append(f"DATE RANGE: {min_date} to {max_date}")
        
    buffer.append("\nCOLUMNS:")
    buffer.append(", ".join(df.columns))
    
    # Add stats for ratings
    if 'rating_overall' in df.columns:
        avg_rating = df['rating_overall'].mean()
        buffer.append(f"\nAVERAGE RATING: {avg_rating:.2f} / 5.0")
        
    # Add a sample of reviews (latest 5)
    buffer.append("\nSAMPLE REVIEWS (LATEST 5):")
    # Ensure sorted by date if possible
    if 'review_date' in df.columns:
        df_sorted = df.sort_values('review_date', ascending=False)
    else:
        df_sorted = df
        
    # Select relevant columns for context
    cols_to_show = ['user_name', 'review_date', 'rating_overall', 'content']
    cols_to_show = [c for c in cols_to_show if c in df.columns]
    
    sample_records = df_sorted.head(5)[cols_to_show].to_dict(orient='records')
    buffer.append(json.dumps(sample_records, indent=2, default=str))
    
    return "\n".join(buffer)

def chat_stream(messages, report_context="", data_context=""):
    """
    Streams response from Gemini model.
    """
    # System Prompt
    system_prompt = f"""
    You are an expert Business Intelligence AI Assistant for specific customer review data.
    
    Your goal is to answer user questions based on the provided context.
    
    --- CONTEXT 1: APP FUNCTIONALITY ---
    You are embedded in the "Southern Frontier Customer Review Intelligence" application.
    - **Home Tab**: Overview of the brand and products (Shu/Sheng Pu'er tea, Tea Cakes, etc.).
    - **Ingestion Tab**: Allows users to upload review screenshots (OCR). Admins can save data; others are read-only (max 10 files).
    - **Database Tab**: A tabular view of all stored reviews. Admins can delete rows. Supports CSV export.
    - **Analysis Tab**: You are here! It shows metrics, sentiment trends, and category ratings. It also allows generating a full AI report (PDF/DOCX/PPTX export).

    --- CONTEXT 2: GENERATED INTELLIGENCE REPORT ---
    (This is the high-level summary report generated by the system)
    {report_context if report_context else "No report generated yet."}
    
    --- CONTEXT 3: UNDERLYING DATA SNAPSHOT ---
    (This is the raw data metrics and valid sample reviews)
    {data_context}
    
    --- INSTRUCTIONS ---
    1. Answer questions about the APP or the DATA.
    2. PRIORITIZE the 'GENERATED INTELLIGENCE REPORT' for conclusions/summaries.
    3. USE the 'UNDERLYING DATA SNAPSHOT' for specific examples or stats.
    4. If asked about how to use the app, refer to the 'APP FUNCTIONALITY' context.
    5. Be professional, concise, and helpful.
    """
    
    # Configure Model
    # Using 'gemini-3-flash-preview' as per project standard
    model = genai.GenerativeModel('gemini-3-flash-preview', system_instruction=system_prompt)
    
    # Convert messages to Gemini format
    history = []
    
    # Provide the last prompt separately to start_chat or generate_content
    # The SDK's start_chat expects history as a list of contents
    
    # We need to filter out the last user message which is the current prompt
    history_messages = messages[:-1]
    current_message = messages[-1]["content"]
    
    # Transform history
    for msg in history_messages:
        role = "user" if msg["role"] == "user" else "model"
        history.append({
            "role": role,
            "parts": [msg["content"]]
        })
        
    chat = model.start_chat(history=history)
    
    response = chat.send_message(current_message, stream=True)
    
    return response
