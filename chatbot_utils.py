import google.generativeai as genai
import streamlit as st
import pandas as pd
import os
import json

def configure_genai():
    """Configures the Gemini API key from Streamlit secrets or environment variables."""
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
    except (FileNotFoundError, KeyError):
        api_key = os.getenv("GOOGLE_API_KEY")
    
    if not api_key:
        return False
    
    genai.configure(api_key=api_key)
    return True

def get_data_context(df):
    """
    Generates a concise summary of the dataframe for the LLM.
    Includes column names, date range, and a sample of recent reviews.
    """
    if df is None or df.empty:
        return "No underlying data available."
    
    buffer = []
    buffer.append(f"TOTAL REVIEWS IN DATASET: {len(df)}")
    
    if 'review_date' in df.columns:
        min_date = df['review_date'].min()
        max_date = df['review_date'].max()
        buffer.append(f"DATE RANGE: {min_date} to {max_date}")
        
    buffer.append("\nCOLUMNS:")
    buffer.append(", ".join(df.columns))
    
    # Add stats for ratings
    if 'rating_overall' in df.columns:
        avg_rating = df['rating_overall'].mean()
        buffer.append(f"\nAVERAGE RATING: {avg_rating:.2f} / 5.0")
        
    # Add a sample of reviews (latest 5)
    buffer.append("\nSAMPLE REVIEWS (LATEST 5):")
    # Ensure sorted by date if possible
    if 'review_date' in df.columns:
        df_sorted = df.sort_values('review_date', ascending=False)
    else:
        df_sorted = df
        
    # Select relevant columns for context
    cols_to_show = ['user_name', 'review_date', 'rating_overall', 'content']
    cols_to_show = [c for c in cols_to_show if c in df.columns]
    
    sample_records = df_sorted.head(5)[cols_to_show].to_dict(orient='records')
    buffer.append(json.dumps(sample_records, indent=2, default=str))
    
    return "\n".join(buffer)

def chat_stream(messages, report_context="", data_context=""):
    """
    Streams response from Gemini model.
    """
    # System Prompt
    system_prompt = f"""
    You are an expert Business Intelligence AI Assistant for specific customer review data.
    
    Your goal is to answer user questions based on the provided context.
    
    --- CONTEXT 1: GENERATED INTELLIGENCE REPORT ---
    (This is the high-level summary report generated by the system)
    {report_context if report_context else "No report generated yet."}
    
    --- CONTEXT 2: UNDERLYING DATA SNAPSHOT ---
    (This is the raw data metrics and valid sample reviews)
    {data_context}
    
    --- INSTRUCTIONS ---
    1. PRIORITIZE the information from the 'GENERATED INTELLIGENCE REPORT' if the user asks about conclusions, summaries, or recommendations.
    2. USE the 'UNDERLYING DATA SNAPSHOT' if the user asks for specific examples, stats, or details that might not be in the high-level report.
    3. You can answer general questions about the reviews shown in the sample.
    4. If the answer is not in the context, politely say you don't have that information.
    5. Be professional, concise, and helpful.
    """
    
    # Configure Model
    # Using 'gemini-3-flash-preview' as per project standard
    model = genai.GenerativeModel('gemini-3-flash-preview', system_instruction=system_prompt)
    
    # Convert messages to Gemini format
    history = []
    
    # Provide the last prompt separately to start_chat or generate_content
    # The SDK's start_chat expects history as a list of contents
    
    # We need to filter out the last user message which is the current prompt
    history_messages = messages[:-1]
    current_message = messages[-1]["content"]
    
    # Transform history
    for msg in history_messages:
        role = "user" if msg["role"] == "user" else "model"
        history.append({
            "role": role,
            "parts": [msg["content"]]
        })
        
    chat = model.start_chat(history=history)
    
    response = chat.send_message(current_message, stream=True)
    
    return response
